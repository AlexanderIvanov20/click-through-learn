{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    brier_score_loss,\n",
    "    confusion_matrix,\n",
    "    log_loss,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, KBinsDiscretizer, MaxAbsScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Paths ----------\n",
    "DATA_DIR = Path(\"../data/raw/avazu\")\n",
    "TRAIN_FILE = DATA_DIR / \"train.gz\"\n",
    "TEST_FILE = DATA_DIR / \"test.gz\"\n",
    "\n",
    "# ---------- Core Column Definitions ----------\n",
    "ID_COL = \"id\"\n",
    "TARGET_COL = \"click\"\n",
    "DATETIME_COL = \"hour\"\n",
    "DATETIME_FORMAT = \"%y%m%d%H\"\n",
    "\n",
    "# ---------- Data Reading & Sampling Controls ----------\n",
    "SAMPLE_FRAC = 0.1  # Use a fraction of the data for faster iteration\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ---------- Data Type Casting ----------\n",
    "# Explicitly setting dtypes during read optimizes memory usage.\n",
    "DTYPE_COLS = {\n",
    "    \"id\": np.int64,\n",
    "    \"click\": np.int8,\n",
    "    \"hour\": np.int64,\n",
    "    \"C1\": np.int32,\n",
    "    \"banner_pos\": np.int8,\n",
    "    \"site_id\": \"category\",\n",
    "    \"site_domain\": \"category\",\n",
    "    \"site_category\": \"category\",\n",
    "    \"app_id\": \"category\",\n",
    "    \"app_domain\": \"category\",\n",
    "    \"app_category\": \"category\",\n",
    "    \"device_id\": \"category\",\n",
    "    \"device_ip\": \"category\",\n",
    "    \"device_model\": \"category\",\n",
    "    \"device_type\": np.int8,\n",
    "    \"device_conn_type\": np.int8,\n",
    "    \"C14\": np.int32,\n",
    "    \"C15\": np.int32,\n",
    "    \"C16\": np.int32,\n",
    "    \"C17\": np.int32,\n",
    "    \"C18\": np.int32,\n",
    "    \"C19\": np.int32,\n",
    "    \"C20\": np.int32,\n",
    "    \"C21\": np.int32,\n",
    "}\n",
    "ALL_COLS = list(DTYPE_COLS.keys())\n",
    "\n",
    "# ---------- Feature Engineering & Modeling Hyperparameters ----------\n",
    "TEST_SIZE = 0.2\n",
    "N_BINS_NUM = 100\n",
    "HASH_N_FEATURES = 2**18\n",
    "RARE_MIN_FREQUENCY = 2000\n",
    "LR_PARAMS = {\n",
    "    \"solver\": \"saga\",\n",
    "    \"class_weight\": \"balanced\",  # Crucial for imbalanced datasets\n",
    "    \"max_iter\": 5000,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "}\n",
    "\n",
    "# ---------- Feature Grouping for Preprocessing Pipelines ----------\n",
    "HIGH_CARD_COLS = [\n",
    "    \"device_id\",\n",
    "    \"device_ip\",\n",
    "    \"device_model\",\n",
    "    \"site_domain\",\n",
    "    \"site_id\",\n",
    "    \"app_id\",\n",
    "]\n",
    "LOW_MED_CARD_COLS = [\n",
    "    \"site_category\",\n",
    "    \"app_category\",\n",
    "    \"app_domain\",\n",
    "    \"banner_pos\",\n",
    "    \"device_type\",\n",
    "    \"device_conn_type\",\n",
    "    \"hod\",\n",
    "    \"dow\",\n",
    "]\n",
    "C_COLS = [\n",
    "    \"C14\",\n",
    "    \"C15\",\n",
    "    \"C16\",\n",
    "    \"C18\",\n",
    "    \"C19\",\n",
    "    \"C20\",\n",
    "    \"C21\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(msg: str):\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] {msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_infer(path: Path, usecols: list[str] = None) -> pd.DataFrame:\n",
    "    return pd.read_csv(path, usecols=usecols, dtype=DTYPE_COLS, compression=\"infer\")\n",
    "\n",
    "\n",
    "log(\"Reading Avazu data...\")\n",
    "\n",
    "df = read_csv_infer(TRAIN_FILE, usecols=ALL_COLS)\n",
    "log(f\"Train read: shape={df.shape}\")\n",
    "\n",
    "# df_test = read_csv_infer(TEST_FILE, usecols=[c for c in ALL_COLS if c != TARGET_COL])\n",
    "# log(f\"Test read: shape={df_test.shape}\")\n",
    "\n",
    "# df = downcast_numeric(df)\n",
    "# df_test = downcast_numeric(df_test)\n",
    "\n",
    "df = df.sample(frac=SAMPLE_FRAC, random_state=RANDOM_STATE)\n",
    "log(f\"Sampled df to fraction={SAMPLE_FRAC}: shape={df.shape}\")\n",
    "\n",
    "# df_test = df_test.sample(frac=SAMPLE_FRAC, random_state=RANDOM_STATE)\n",
    "# log(f\"Sampled df_test to fraction={SAMPLE_FRAC}: shape={df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    s = df[DATETIME_COL].astype(str).str.zfill(8)\n",
    "    ts = pd.to_datetime(s, format=DATETIME_FORMAT, errors=\"coerce\", utc=True)\n",
    "    df = df.assign(hod=ts.dt.hour, dow=ts.dt.day_of_week)\n",
    "    return df\n",
    "\n",
    "\n",
    "log(\"Creating time-based features (hod, dow)...\")\n",
    "\n",
    "df = add_time_features(df)\n",
    "\n",
    "log(\"Time-based features created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_TO_DROP = [\n",
    "    ID_COL,\n",
    "    TARGET_COL,\n",
    "    DATETIME_COL,\n",
    "    \"C1\",\n",
    "    \"C17\",\n",
    "]\n",
    "\n",
    "X = df.drop(columns=COLS_TO_DROP, axis=1)\n",
    "y = df[TARGET_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_tokens_rowwise(X: pd.DataFrame) -> np.ndarray:\n",
    "    X = pd.DataFrame(X).astype(\"string\")\n",
    "    arrays = [np.char.add(f\"{c}=\", X[c].to_numpy(dtype=str)) for c in X.columns]\n",
    "\n",
    "    joined = arrays[0]\n",
    "    for a in arrays[1:]:\n",
    "        joined = np.char.add(np.char.add(joined, \" \"), a)\n",
    "\n",
    "    return joined\n",
    "\n",
    "\n",
    "high_card_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"to_tokens\", FunctionTransformer(join_tokens_rowwise, validate=False)),\n",
    "        (\n",
    "            \"hash\",\n",
    "            HashingVectorizer(\n",
    "                n_features=HASH_N_FEATURES,\n",
    "                alternate_sign=False,\n",
    "                lowercase=False,\n",
    "                token_pattern=r\"[^ ]+\",\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "low_med_card_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"one_hot_encoder\",\n",
    "            OneHotEncoder(\n",
    "                handle_unknown=\"infrequent_if_exist\",\n",
    "                min_frequency=RARE_MIN_FREQUENCY,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "c_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"kbins\",\n",
    "            KBinsDiscretizer(\n",
    "                n_bins=N_BINS_NUM,\n",
    "                strategy=\"quantile\",\n",
    "                encode=\"ordinal\",\n",
    "                quantile_method=\"averaged_inverted_cdf\",\n",
    "            ).set_output(transform=\"pandas\"),\n",
    "        ),\n",
    "        (\"woe\", ce.WOEEncoder(cols=C_COLS, random_state=RANDOM_STATE)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"high_card_cols\", high_card_pipeline, HIGH_CARD_COLS + C_COLS),\n",
    "        (\"low_med_car_cols\", low_med_card_pipeline, LOW_MED_CARD_COLS),\n",
    "        # (\"c_cols\", c_pipeline, C_COLS),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "log(f\"X train: {X_train.shape=}\")\n",
    "log(f\"y train: {y_train.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(**LR_PARAMS)\n",
    "model = Pipeline(\n",
    "    steps=[\n",
    "        (\"features\", preprocessor),\n",
    "        (\"scale\", MaxAbsScaler()),\n",
    "        (\"clf\", logreg),\n",
    "    ]\n",
    ")\n",
    "\n",
    "log(\"Starting model training...\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "log(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"Generating predictions on the test set...\")\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "pr_auc = average_precision_score(y_test, y_pred_proba)\n",
    "logloss = log_loss(y_test, y_pred_proba)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "log(f\"ROC-AUC: {roc_auc:.6f}\")\n",
    "log(f\"PR-AUC: {pr_auc:.6f}\")\n",
    "log(f\"LogLoss: {logloss:.6f}\")\n",
    "log(f\"Accuracy: {acc:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tscv = TimeSeriesSplit(n_splits=5)\n",
    "# param_grid = {\n",
    "#     \"clf__C\": np.logspace(-3, 2, 6),\n",
    "#     \"clf__max_iter\": [1000, 2000],\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(\n",
    "#     estimator=model,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring=\"roc_auc\",\n",
    "#     cv=3,\n",
    "#     refit=True,\n",
    "#     verbose=2,\n",
    "# )\n",
    "# grid.fit(X, y)\n",
    "\n",
    "# log(f\"Best params: {grid.best_params_}\")\n",
    "# log(f\"Best CV ROC-AUC: {round(grid.best_score_, 6)}\")\n",
    "\n",
    "# best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig_roc_avazu = go.Figure()\n",
    "fig_roc_avazu.add_trace(\n",
    "    go.Scatter(x=fpr, y=tpr, mode=\"lines\", name=f\"ROC (AUC={roc_auc:.4f})\")\n",
    ")\n",
    "fig_roc_avazu.add_trace(\n",
    "    go.Scatter(x=[0, 1], y=[0, 1], mode=\"lines\", name=\"Chance\", line=dict(dash=\"dash\"))\n",
    ")\n",
    "fig_roc_avazu.update_layout(\n",
    "    title=\"ROC Curve\",\n",
    "    xaxis_title=\"False Positive Rate\",\n",
    "    yaxis_title=\"True Positive Rate\",\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1,\n",
    "    ),\n",
    ")\n",
    "fig_roc_avazu.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, rec, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "ap = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "fig_pr_avazu = go.Figure()\n",
    "fig_pr_avazu.add_trace(\n",
    "    go.Scatter(x=rec, y=prec, mode=\"lines\", name=f\"PR (AP={ap:.4f})\")\n",
    ")\n",
    "fig_pr_avazu.update_layout(\n",
    "    title=\"Precision-Recall Curve\",\n",
    "    xaxis_title=\"Recall\",\n",
    "    yaxis_title=\"Precision\",\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1,\n",
    "    ),\n",
    ")\n",
    "fig_pr_avazu.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "cm_df = pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Pred 0\", \"Pred 1\"])\n",
    "\n",
    "fig_cm_avazu = go.Figure(\n",
    "    data=go.Heatmap(\n",
    "        z=cm_df.values,\n",
    "        text=cm_df.values,\n",
    "        texttemplate=\"%{text}\",\n",
    "        hovertemplate=\"Row: %{y}<br>Col: %{x}<br>Count: %{z}<extra></extra>\",\n",
    "    )\n",
    ")\n",
    "fig_cm_avazu.update_layout(\n",
    "    title=\"Confusion Matrix (Threshold = 0.5)\",\n",
    "    xaxis_title=\"Predicted\",\n",
    "    yaxis_title=\"Actual\",\n",
    ")\n",
    "fig_cm_avazu.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true, prob_pred = calibration_curve(\n",
    "    y_test, y_pred_proba, n_bins=10, strategy=\"quantile\"\n",
    ")\n",
    "brier = float(brier_score_loss(y_test, y_pred_proba))\n",
    "\n",
    "fig_cal_avazu = go.Figure()\n",
    "fig_cal_avazu.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, 1],\n",
    "        y=[0, 1],\n",
    "        mode=\"lines\",\n",
    "        name=\"Perfectly Calibrated\",\n",
    "        line=dict(dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "fig_cal_avazu.add_trace(\n",
    "    go.Scatter(x=prob_pred, y=prob_true, mode=\"lines+markers\", name=\"Model\")\n",
    ")\n",
    "fig_cal_avazu.update_layout(\n",
    "    title=f\"Calibration Curve{' — Brier: ' + f'{brier:.5f}' if brier is not None else ''}\",\n",
    "    xaxis_title=\"Predicted Probability\",\n",
    "    yaxis_title=\"Observed Frequency\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    ")\n",
    "fig_cal_avazu.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "click-through-learn-j_p1wCCt-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
